{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "housing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gyjuU-CkX5TE"
      },
      "source": [
        "# HOUSING KAGGLE REGRESSION PROBLEM\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iiXZLrKKo9N5"
      },
      "source": [
        "### First regression model\n",
        "OOTB Random Forest Regressor to be used as our ruler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83wWbLH90ms1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CyX29qpfEn9_",
        "colab": {}
      },
      "source": [
        "# loading dataset into the script\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LeoFernanndes/datasets/master/housing_train.csv')\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtDM84ohEn-G",
        "colab": {}
      },
      "source": [
        "# a generic method to arrange the variables\n",
        "housing = df.copy()\n",
        "\n",
        "# starting by filling the blank spaces \n",
        "for column in housing.columns:\n",
        "    if housing[column].dtype != 'object':\n",
        "        housing[column].fillna(housing[column].mean(), inplace= True)\n",
        "    else:\n",
        "        housing[column] = housing[column].astype('str')\n",
        "        housing[column].fillna(housing[column].mode(), inplace= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zdY4xgRqEn-N",
        "colab": {}
      },
      "source": [
        "## fitting the first regression model \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# splitting the dependent (predictor) and dependent (target) features\n",
        "x = housing.drop(['SalePrice'], axis= 1)\n",
        "y = housing['SalePrice']\n",
        "\n",
        "# applying label encoding\n",
        "le = LabelEncoder()\n",
        "for column in x.columns:\n",
        "    if x[column].dtype == 'object':\n",
        "        x[column] = le.fit_transform(x[column])\n",
        "\n",
        "# splitting the data into train and test\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size= 0.2, random_state= 55)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Az23RrjmEn-T",
        "outputId": "ad5214ff-5da6-4490-a578-9b29365b31c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calling the regressor\n",
        "reg1 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "\n",
        "# fitting the model\n",
        "reg1.fit(x_treino, y_treino)\n",
        "\n",
        "# making the prediction of target in trein set\n",
        "prev = reg1.predict(x_teste)\n",
        "\n",
        "\n",
        "# error evaluation\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "erro = np.sqrt(mean_squared_log_error(y_teste, prev))\n",
        "erro"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13568714490519806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktuyZBJwEn-W",
        "colab": {}
      },
      "source": [
        "# making the predictions over submission set\n",
        "# loading submission data\n",
        "url_data = 'https://raw.githubusercontent.com/LeoFernanndes/datasets/master/housing_test.csv'\n",
        "data = pd.read_csv(url_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n7SGogTzEn-a",
        "colab": {}
      },
      "source": [
        "# filling in the gaps in the same manner as used in the trein set\n",
        "for column in data.columns:\n",
        "    if data[column].dtype != 'object':\n",
        "        data[column].fillna(data[column].mean(), inplace= True)\n",
        "    else:\n",
        "        data[column] = data[column].astype('str')\n",
        "        data[column].fillna(data[column].mode(), inplace= True)\n",
        "\n",
        "# using label encoder over the test set the same way as used in trein set \n",
        "le = LabelEncoder()\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        data[column] = le.fit_transform(data[column])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zJGc0002En-d",
        "colab": {}
      },
      "source": [
        "# df for kaggle evaluation\n",
        "final = reg1.predict(data)\n",
        "envio = pd.DataFrame({'Id': data['Id'], 'SalePrice': final})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JAaapySmEn-g",
        "colab": {}
      },
      "source": [
        "# saving the df in a csv to be uploaded\n",
        "\n",
        "#path = r'C:\\Users\\Avell\\Desktop\\Python\\github\\datasets'\n",
        "#nome = '\\housing_submission_1.csv'\n",
        "#envio.to_csv(path+nome, index= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uPF-40m4piQJ"
      },
      "source": [
        "Of corse we didn't expect here anything extremely accurate for some reasons:\n",
        "* The model itself was implemented just out of the box\n",
        "* The approach to fill the missing values using mode to categorical features and mean in the case of numerical ones didn't take in account any exploratory analysis of the variables\n",
        "* No methodology for feature engineering and in order to tune model precision by finding cerrelations or opportunities to dimensional reduction\n",
        "* All categorical features were encoded with the same method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "amWBKB4LjpV2"
      },
      "source": [
        "## Model improvement attempts\n",
        "### Second regression model scoring rmsle 0.1466"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "crh46d0MXi5K",
        "colab": {}
      },
      "source": [
        "# checando com o feature importance\n",
        "featimp = pd.Series(reg1.feature_importances_, index= x_teste.columns).sort_values(ascending=False)\n",
        "featimp.index\n",
        "feat_upper = featimp.index[0: 24]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJTVDj33Xi5P",
        "colab": {}
      },
      "source": [
        "# novo x\n",
        "x2 = x.copy()\n",
        "y2 = y.copy()\n",
        "\n",
        "# novo encoding\n",
        "le2 = LabelEncoder()\n",
        "for column in x2.columns:\n",
        "    if x2[column].dtype == 'object':\n",
        "        x2[column] = le2.fit_transform(x2[column])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6p0-lj_Xi5T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f67111f-c402-4e03-e1f7-d00e5cba7027"
      },
      "source": [
        "# chamando o modelo\n",
        "reg2 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
        "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "\n",
        "x2_treino, x2_teste, y2_treino, y2_teste = train_test_split(x2, y2, test_size= 0.2, random_state= 11)\n",
        "\n",
        "# ajustando um modelo\n",
        "reg2.fit(x2_treino[feat_upper], y2_treino)\n",
        "\n",
        "# fazendo a previsao\n",
        "prev2 = reg2.predict(x2_teste[feat_upper])\n",
        "\n",
        "\n",
        "# avaliando o erro\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "error2 = np.sqrt(mean_squared_log_error(y2_teste, prev2))\n",
        "error2\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1443646655720345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZDrcXsS6Ge0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ced77088-0ad9-47c4-bd89-0ae0bd168951"
      },
      "source": [
        "y_axis = []\n",
        "x_axis = []\n",
        "\n",
        "for m in(range(len(featimp.index))):\n",
        "\n",
        "  error2_ = 0\n",
        "  n = 5\n",
        "  \n",
        "  for i in(range(n)):\n",
        "    # chamando o modelo\n",
        "    reg2 = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "              max_features='auto', max_leaf_nodes=None,\n",
        "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "              min_samples_leaf=1, min_samples_split=2,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
        "              oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "\n",
        "    x2_treino, x2_teste, y2_treino, y2_teste = train_test_split(x2, y2, test_size= 0.2, random_state= i**2)\n",
        "\n",
        "    # ajustando um modelo\n",
        "    reg2.fit(x2_treino[featimp.index[0: m+1]], y2_treino)\n",
        "\n",
        "    # fazendo a previsao\n",
        "    prev2 = reg2.predict(x2_teste[featimp.index[0: m+1]])\n",
        "\n",
        "\n",
        "    # avaliando o erro\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    import numpy as np\n",
        "\n",
        "\n",
        "    error2 = np.sqrt(mean_squared_log_error(y2_teste, prev2))\n",
        "    #print(error2)\n",
        "    error2_ += error2\n",
        "\n",
        "  y_axis.append(error2_/n)\n",
        "  x_axis.append(m)\n",
        "  print(m, error2_/n)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.2213524143735138\n",
            "1 0.21525065706019353\n",
            "2 0.18195680956610813\n",
            "3 0.170858201521555\n",
            "4 0.16722131205634874\n",
            "5 0.161737196146741\n",
            "6 0.16020528201318013\n",
            "7 0.15922655647518869\n",
            "8 0.157491264310203\n",
            "9 0.1509195760680191\n",
            "10 0.15201801656423045\n",
            "11 0.1526665808129707\n",
            "12 0.14843617273024728\n",
            "13 0.1459006181914338\n",
            "14 0.1473665677295048\n",
            "15 0.14579156812940736\n",
            "16 0.1471499895719634\n",
            "17 0.1461735872676941\n",
            "18 0.14674172001927394\n",
            "19 0.14512919901430196\n",
            "20 0.146947171763449\n",
            "21 0.14715363964461173\n",
            "22 0.14509171321130637\n",
            "23 0.14580995941881342\n",
            "24 0.1459527078104604\n",
            "25 0.14328048330596235\n",
            "26 0.14217048733796375\n",
            "27 0.1421051062370437\n",
            "28 0.1425451335558059\n",
            "29 0.1414952015536075\n",
            "30 0.14265805207548604\n",
            "31 0.14192043189068676\n",
            "32 0.14142116805433805\n",
            "33 0.14161825106388087\n",
            "34 0.14167671347488375\n",
            "35 0.14082550781521908\n",
            "36 0.14104190571099692\n",
            "37 0.14195474591108403\n",
            "38 0.14146467561843928\n",
            "39 0.14231126069605643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-bc89a5ba7a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ajustando um modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mreg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_treino\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# fazendo a previsao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuuPyuj1KiIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error_df = pd.DataFrame({'n of features': x_axis,\n",
        "                         'error': y_axis}).sort_values(by= ['error'], ascending= True)\n",
        "\n",
        "error_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pn130ZxIGVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('RMSLE')\n",
        "plt.xlabel('Number of sorted features')\n",
        "plt.ylabel('Error')\n",
        "plt.plot(x_axis, y_axis)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsfFvU2Vw4V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/LeoFernanndes/datasets/master/housing_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sLrvseixAHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# exploring data \n",
        "\n",
        "for column in dataframe.columns:\n",
        "  if dataframe[column].dtype == 'object':\n",
        "    print(dataframe[column].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNGBx6xUWYHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featimp.index"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}