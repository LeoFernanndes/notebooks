{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "hackathon_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoFernanndes/notebooks/blob/master/hackathon_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pv_TeG_YJC5",
        "colab_type": "code",
        "outputId": "b31d5757-d711-40be-d1ba-d5c01fd1e59b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "24 metricas em modelos de classificação\n",
        "https://neptune.ml/blog/evaluation-metrics-binary-classification\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n24 metricas em modelos de classificação\\nhttps://neptune.ml/blog/evaluation-metrics-binary-classification\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oP8MzDdhUpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classificador_hackathon(df_prev):\n",
        "    \n",
        "    '''\n",
        "    funcao a ser usada para classificar as entradas em  uma base de dados de um sistema de oferta de crédito\n",
        "\n",
        "    df_prev: DataFrame a com as entradas a terem sua prepensao ao aceite prevista\n",
        "    \n",
        "    '''\n",
        "    \n",
        "\n",
        "    # subindo o DataFrame que vai ser usado para treinar o modelo\n",
        "    import pandas as pd \n",
        "    \n",
        "    ulr_full = 'https://raw.githubusercontent.com/LeoFernanndes/datasets/master/bank_full.csv'\n",
        "    url = 'https://raw.githubusercontent.com/LeoFernanndes/datasets/master/bank.csv' \n",
        "    \n",
        "    # dados de treino e dados de teste\n",
        "    data_full = pd.read_csv(ulr_full, sep= ';', encoding= 'utf-8')\n",
        "    data = pd.read_csv(url, sep= ';', encoding= 'utf-8')\n",
        "    \n",
        "    # imprimindo os nomes das colunas disponiveis para facilitar consulta e manipulação\n",
        "    ref = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
        "       'previous', 'poutcome']\n",
        "    \n",
        "    colunas = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
        "       'previous', 'poutcome']\n",
        "    \n",
        "    # separando um pedaço do bank_full pra usar como dados de treino\n",
        "    data_full_treino = data\n",
        "    data_full_teste = data_full\n",
        "    \n",
        "    # usando o label encoder para transformar as variaveis categorias em numericas e assim poder treinar o modelo\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    atributos = data_full_treino.copy()[colunas]\n",
        "    rotulos = data_full_treino.copy()['y']\n",
        "    \n",
        "    label_encoder = LabelEncoder()\n",
        "    for column in atributos.columns:\n",
        "        if atributos[column].dtype == 'object':\n",
        "            atributos[column] = label_encoder.fit_transform(atributos[column])        \n",
        "    \n",
        "    # chamando o classificador\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier()\n",
        "    clf.fit(atributos, rotulos)\n",
        "    \n",
        "    \n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    \n",
        "    # avaliação de resultados\n",
        "    pontuacao = cross_val_score(clf, atributos, rotulos, cv=10, scoring = \"accuracy\")\n",
        "    print('Minimo', pontuacao.min(), '\\n')\n",
        "    print('Média ', pontuacao.mean(), '\\n')\n",
        "    print('Maximo', pontuacao.max(), '\\n')\n",
        "    print('Desvio padrão ', pontuacao.std(), '\\n')\n",
        "    \n",
        "    \n",
        "    \n",
        "    df_prev1 = df_prev.copy()[colunas]\n",
        "    for column in df_prev.columns:\n",
        "        if df_prev1[column].dtype == 'object':\n",
        "            df_prev1[column] = label_encoder.fit_transform(df_prev1[column])\n",
        "    \n",
        "    \n",
        "    resultado = clf.predict(df_prev1)\n",
        "    \n",
        "    featimp = pd.Series(clf.feature_importances_, index= atributos.columns).sort_values(ascending=False)\n",
        "    \n",
        "    matrix = confusion_matrix(resultado, data_full_teste['y'])\n",
        "\n",
        "    print(featimp, '\\n')\n",
        "    print('Confusion matrix \\n', matrix, '\\n')\n",
        "    \n",
        "    precision = matrix[1][1] / (matrix[0][1] + matrix[1][1])\n",
        "    print(precision)\n",
        "    \"\"\"\n",
        "    # precisão, recall e f1 para a avaliação da utilidade do modelo \n",
        "    recall = 1827 / (1827 + 3462)\n",
        "    precision = 1827 / (1827 + 788)\n",
        "    f1 = 2 * recall * precision / (recall + precision)\n",
        "    print('Precision \\n', precision, '\\n', 'Recall \\n', recall, '\\n', 'F1 score \\n', f1)\n",
        "    \"\"\"\n",
        "\n",
        "    #resultado1 = pd.DataFrame(resultado.astype(object), columns= ['accepts'])\n",
        "    #final = df_prev.append(resultado1)\n",
        "    \n",
        "    return resultado\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlplA6rCYJDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_full = pd.read_csv('https://raw.githubusercontent.com/LeoFernanndes/datasets/master/bank_full.csv', sep= ';', encoding= 'utf-8')\n",
        "entrada = data_full.drop(['y'], axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X6VbnOiYJDH",
        "colab_type": "code",
        "outputId": "71204823-6cce-46ed-fac7-dbe67f086420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "previsao = classificador_hackathon(entrada)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Minimo 0.8805309734513275 \n",
            "\n",
            "Média  0.8940504795952254 \n",
            "\n",
            "Maximo 0.911504424778761 \n",
            "\n",
            "Desvio padrão  0.008415010265735066 \n",
            "\n",
            "duration     0.283623\n",
            "balance      0.113470\n",
            "age          0.101043\n",
            "month        0.094673\n",
            "day          0.092602\n",
            "pdays        0.053224\n",
            "job          0.046659\n",
            "poutcome     0.045877\n",
            "marital      0.031475\n",
            "campaign     0.031272\n",
            "previous     0.025477\n",
            "education    0.025223\n",
            "housing      0.024498\n",
            "contact      0.018648\n",
            "loan         0.009056\n",
            "default      0.003179\n",
            "dtype: float64 \n",
            "\n",
            "Confusion matrix \n",
            " [[39001  3407]\n",
            " [  921  1882]] \n",
            "\n",
            "0.35583286065418795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_CFTnuzphSg",
        "colab_type": "code",
        "outputId": "ad274b2b-a263-4f8c-8c2a-21f732e38ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "## Backup da função\n",
        "## analisando o modelo para aumentar o f1 e implementar uma melhor solução dentro da função de classificação\n",
        "\n",
        " # subindo o DataFrame que vai ser usado para treinar o modelo\n",
        "import pandas as pd \n",
        "\n",
        "ulr_full = 'https://raw.githubusercontent.com/LeoFernanndes/datasets/master/bank_full.csv'\n",
        "data_full = pd.read_csv(ulr_full, sep= ';', encoding= 'utf-8')\n",
        "\n",
        "# imprimindo os nomes das colunas disponiveis para facilitar consulta e manipulação\n",
        "ref = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "    'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
        "    'previous', 'poutcome']\n",
        "\n",
        "# colunas a serem usadas no modelo\n",
        "colunas = ['duration', 'age', 'balance', 'day', 'month', 'poutcome', 'job']\n",
        "\n",
        "# separando um pedaço do bank_full pra usar como dados de treino\n",
        "data_full_treino = data_full\n",
        "\n",
        "# usando o label encoder para transformar as variaveis categorias em numericas e assim poder treinar o modelo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "atributos = data_full_treino.copy()[colunas]\n",
        "rotulos = data_full_treino.copy()['y']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for column in atributos.columns:\n",
        "    if atributos[column].dtype == 'object':\n",
        "        atributos[column] = label_encoder.fit_transform(atributos[column])        \n",
        "\n",
        "# dividindo o dataset em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(atributos, rotulos, train_size= 0.20, random_state= 55)\n",
        "\n",
        "# chamando o classificador\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators= 10)\n",
        "clf.fit(x_treino, y_treino)\n",
        "\n",
        "# validação cruzada\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "pontuacao = cross_val_score(clf, atributos, rotulos, cv=10, scoring = \"accuracy\")\n",
        "\n",
        "print('Desempenho Cross Validation \\n',\n",
        "      'Minimo', pontuacao.min(), '\\n',\n",
        "      'Média ', pontuacao.mean(), '\\n',\n",
        "      'Maximo', pontuacao.max(), '\\n',\n",
        "      'Desvio padrão ', pontuacao.std(), '\\n')\n",
        "\n",
        "# ajusto do modelo aos dados de treino para previsão\n",
        "resultado = clf.predict(x_teste)\n",
        "\n",
        "# lista dos atributos mais relevantes \n",
        "featimp = pd.Series(clf.feature_importances_, index= atributos.columns).sort_values(ascending=False)\n",
        "print('Feature importance \\n',\n",
        "      featimp, '\\n')\n",
        "\n",
        "# confusion matrix \n",
        "matrix = confusion_matrix(resultado, y_teste)\n",
        "print('Confusion matrix \\n', matrix, '\\n')\n",
        "\n",
        "# metricas de desempenho\n",
        "accuracy = accuracy_score(resultado, y_teste)\n",
        "precision = matrix[1][1] / (matrix[1][0] + matrix[1][1])\n",
        "recall = matrix[1][1] / (matrix[0][1] + matrix[1][1])\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "print('Accuracy \\n', accuracy, '\\n',\n",
        "      'Precision \\n', precision, '\\n',\n",
        "      'Recall \\n', recall, '\\n',\n",
        "      'F1 score \\n', f1_score, '\\n')\n",
        "\n",
        "# verificando os valores reais\n",
        "aceite = data_full.loc[(data_full['y'] == 'yes')]['y'].count()\n",
        "print('Proporção real aceita \\n',\n",
        "      aceite/len(data_full), '\\n',\n",
        "      'proporção real rejeita \\n',\n",
        "      1 - aceite/len(data_full))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desempenho Cross Validation \n",
            " Minimo 0.46936518469365185 \n",
            " Média  0.7592769258847911 \n",
            " Maximo 0.8730650154798761 \n",
            " Desvio padrão  0.11843804502583768 \n",
            "\n",
            "Feature importance \n",
            " duration    0.316447\n",
            "balance     0.149602\n",
            "age         0.144631\n",
            "day         0.127233\n",
            "month       0.120240\n",
            "poutcome    0.074691\n",
            "job         0.067157\n",
            "dtype: float64 \n",
            "\n",
            "Confusion matrix \n",
            " [[30963  2749]\n",
            " [ 1030  1427]] \n",
            "\n",
            "Accuracy \n",
            " 0.8955182614946501 \n",
            " Precision \n",
            " 0.5807895807895808 \n",
            " Recall \n",
            " 0.3417145593869732 \n",
            " F1 score \n",
            " 0.4302728780340721 \n",
            "\n",
            "Proporção real aceita \n",
            " 0.11698480458295547 \n",
            " proporção real rejeita \n",
            " 0.8830151954170445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8gzrBJCPT0",
        "colab_type": "code",
        "outputId": "21664f2c-011d-4736-d82e-02e134290a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "## analisando o modelo para aumentar o f1 e implementar uma melhor solução dentro da função de classificação\n",
        "\n",
        "# subindo o DataFrame que vai ser usado para treinar o modelo\n",
        "import pandas as pd \n",
        "\n",
        "ulr_full = 'https://raw.githubusercontent.com/LeoFernanndes/datasets/master/bank_full.csv'\n",
        "data_full = pd.read_csv(ulr_full, sep= ';', encoding= 'utf-8')\n",
        "\n",
        "# imprimindo os nomes das colunas disponiveis para facilitar consulta e manipulação\n",
        "ref = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
        "    'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
        "    'previous', 'poutcome']\n",
        "\n",
        "# colunas a serem usadas no modelo\n",
        "colunas = ['duration', 'age', 'balance', 'day', 'month', 'poutcome', 'job']\n",
        "\n",
        "# separando um pedaço do bank_full pra usar como dados de treino\n",
        "data_full_treino = data_full\n",
        "\n",
        "# usando o label encoder para transformar as variaveis categorias em numericas e assim poder treinar o modelo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "atributos = data_full_treino.copy()[colunas]\n",
        "rotulos = data_full_treino.copy()['y']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for column in atributos.columns:\n",
        "    if atributos[column].dtype == 'object':\n",
        "        atributos[column] = label_encoder.fit_transform(atributos[column])        \n",
        "\n",
        "# dividindo o dataset em treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(atributos, rotulos, train_size= 0.20, random_state= 55)\n",
        "\n",
        "# chamando o classificador\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators= 10)\n",
        "clf.fit(x_treino, y_treino)\n",
        "\n",
        "# validação cruzada\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# esse modelo de avaliação de cross validation é pouco interessante, mas ja indica que o modelo é pior que chutar não pra tudo\n",
        "# para avaliar recall e precision, provavelmente tenho que mudar as labels de ['y'] para numéricas\n",
        "pontuacao1 = cross_val_score(clf, atributos, rotulos, cv=10, scoring = \"accuracy\")\n",
        "\n",
        "print('Desempenho Cross Validation \\n',\n",
        "      'Minimo', pontuacao1.min(), '\\n',\n",
        "      'Média ', pontuacao1.mean(), '\\n',\n",
        "      'Maximo', pontuacao1.max(), '\\n',\n",
        "      'Desvio padrão ', pontuacao1.std(), '\\n')\n",
        "\n",
        "# ajuste do modelo aos dados de treino para previsão\n",
        "resultado = clf.predict(x_teste)\n",
        "\n",
        "# lista dos atributos mais relevantes \n",
        "featimp = pd.Series(clf.feature_importances_, index= atributos.columns).sort_values(ascending=False)\n",
        "print('Feature importance \\n',\n",
        "      featimp, '\\n')\n",
        "\n",
        "# confusion matrix \n",
        "matrix = confusion_matrix(resultado, y_teste)\n",
        "print('Confusion matrix \\n', matrix, '\\n')\n",
        "\n",
        "# metricas de desempenho\n",
        "accuracy = accuracy_score(resultado, y_teste)\n",
        "precision = matrix[1][1] / (matrix[1][0] + matrix[1][1])\n",
        "recall = matrix[1][1] / (matrix[0][1] + matrix[1][1])\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "print('Accuracy \\n', accuracy, '\\n',\n",
        "      'Precision \\n', precision, '\\n',\n",
        "      'Recall \\n', recall, '\\n',\n",
        "      'F1 score \\n', f1_score, '\\n')\n",
        "\n",
        "# verificando os valores reais\n",
        "aceite = data_full.loc[(data_full['y'] == 'yes')]['y'].count()\n",
        "print('Proporção real aceita \\n',\n",
        "      aceite/len(data_full), '\\n',\n",
        "      'proporção real rejeita \\n',\n",
        "      1 - aceite/len(data_full))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Desempenho Cross Validation \n",
            " Minimo 0.46228710462287104 \n",
            " Média  0.7641218139316333 \n",
            " Maximo 0.8679787704555506 \n",
            " Desvio padrão  0.11682473162179623 \n",
            "\n",
            "Feature importance \n",
            " duration    0.329347\n",
            "balance     0.150184\n",
            "age         0.145885\n",
            "day         0.120411\n",
            "month       0.114210\n",
            "poutcome    0.077749\n",
            "job         0.062214\n",
            "dtype: float64 \n",
            "\n",
            "Confusion matrix \n",
            " [[30974  2768]\n",
            " [ 1019  1408]] \n",
            "\n",
            "Accuracy \n",
            " 0.8952970776078962 \n",
            " Precision \n",
            " 0.5801400906468892 \n",
            " Recall \n",
            " 0.3371647509578544 \n",
            " F1 score \n",
            " 0.42647281538694537 \n",
            "\n",
            "Proporção real aceita \n",
            " 0.11698480458295547 \n",
            " proporção real rejeita \n",
            " 0.8830151954170445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}